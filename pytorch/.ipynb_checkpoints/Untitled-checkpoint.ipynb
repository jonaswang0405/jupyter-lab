{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88349683-c7b0-4d46-ae58-eb4871fe303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b05a0f-dc63-49c7-91da-665d30e6e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([60., 97.])\n",
      "tensor([-4.,  4.])\n"
     ]
    }
   ],
   "source": [
    "#model=torchvision.models.resnet18(pretrained=True)\n",
    "a=torch.tensor([2.,3.],requires_grad=True)\n",
    "b=torch.tensor([6.,4.],requires_grad=True)\n",
    "Q=3*a**3-b**2+2*a*b*2\n",
    "external_grad=torch.tensor([1.,1.])\n",
    "Q.backward(gradient=external_grad) #\n",
    "print(a.grad)#计算Q对a的偏导\n",
    "print(b.grad)#计算Q对b的偏导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8bd632-839b-4a8d-b4a3-2a50df5fb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399e8dd0-4e2f-4414-a099-f1c07f8d4b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "training_data=datasets.FashionMNIST(root='data',\n",
    "                                    train=True,\n",
    "                                    download=True,\n",
    "                                    transform=ToTensor(),)\n",
    "test_data=datasets.FashionMNIST(root='data',\n",
    "                               train=False,\n",
    "                               download=True,\n",
    "                               transform=ToTensor(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e195bbb-eac8-4743-9321-026c1034c944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x[N,C,H,W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y： torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "train_dataloader=DataLoader(training_data,batch_size=batch_size)  #每64个图片为一组，进行训练\n",
    "test_dataloader=DataLoader(test_data,batch_size=batch_size)\n",
    "for x,y in test_dataloader:\n",
    "    print('Shape of x[N,C,H,W]:',x.shape)\n",
    "    print('Shape of y：',y.shape,y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce19c164-0d82-4335-8967-bcdfbf820b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using {} device'.format(device))\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork,self).__init__()  #super调用父类的方法，此次为nn.Module的方法\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "                                            nn.Linear(28*28,512),   #28*28：输入特征向量，512：输出特征向量\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(512,512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(512,10))\n",
    "    def forward (self,x):\n",
    "        x=self.flatten(x)\n",
    "        logits=self.linear_relu_stack(x)   #linear_relu_stack为前7行定义的self.linear_relu_stack，用以对每个x执行linear_relu_stack函数的计算\n",
    "        return logits\n",
    "    \n",
    "model=NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86394606-2979-4737-8591-68d691ba7d28",
   "metadata": {},
   "source": [
    "# Optimizing the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd927a0-45b5-499e-8ec6-a3d3d4c05857",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b013cc8a-cd0c-416f-b2ee-a76460c88cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,model,loss_fn,optimizer):\n",
    "    size=len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch,(x,y) in enumerate(dataloader):\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        \n",
    "        #compute prediction error\n",
    "        pred=model(x)\n",
    "        loss=loss_fn(pred,y)\n",
    "        \n",
    "        #backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch%100==0:\n",
    "            loss,current=loss.item(),batch*len(x)\n",
    "            print(f'loss:{loss:>7f} [{current:>5d}/{size :>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dce9414-031e-4f0e-9c26-991fcc95ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader,model,loss_fn):\n",
    "    size=len(dataloader.dataset)\n",
    "    num_batches=len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss,correct=0,0\n",
    "    with torch.no_grad():\n",
    "        for x ,y in dataloader:\n",
    "            x,y=x.to(device),y.to(device)\n",
    "            pred=model(x)\n",
    "            test_loss_=loss_fn(pred,y).item()\n",
    "            correct +=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss/=num_batches\n",
    "    correct/=size\n",
    "    print(f'Test Error:\\n Accuracy:{(100*correct):>0.1f}%, Avg loss:{test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6006f55-d346-4471-b640-11268028a93c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1\n",
      "--------------\n",
      "loss:2.309947 [    0/60000]\n",
      "loss:2.291602 [ 6400/60000]\n",
      "loss:2.272736 [12800/60000]\n",
      "loss:2.261524 [19200/60000]\n",
      "loss:2.253564 [25600/60000]\n",
      "loss:2.219537 [32000/60000]\n",
      "loss:2.231924 [38400/60000]\n",
      "loss:2.196790 [44800/60000]\n",
      "loss:2.200413 [51200/60000]\n",
      "loss:2.167365 [57600/60000]\n",
      "Test Error:\n",
      " Accuracy:46.9%, Avg loss:0.000000\n",
      "\n",
      "Epoch2\n",
      "--------------\n",
      "loss:2.176572 [    0/60000]\n",
      "loss:2.158749 [ 6400/60000]\n",
      "loss:2.104409 [12800/60000]\n",
      "loss:2.116866 [19200/60000]\n",
      "loss:2.079594 [25600/60000]\n",
      "loss:2.015186 [32000/60000]\n",
      "loss:2.050142 [38400/60000]\n",
      "loss:1.969695 [44800/60000]\n",
      "loss:1.978782 [51200/60000]\n",
      "loss:1.909867 [57600/60000]\n",
      "Test Error:\n",
      " Accuracy:59.5%, Avg loss:0.000000\n",
      "\n",
      "Epoch3\n",
      "--------------\n",
      "loss:1.940635 [    0/60000]\n",
      "loss:1.906246 [ 6400/60000]\n",
      "loss:1.790090 [12800/60000]\n",
      "loss:1.826541 [19200/60000]\n",
      "loss:1.734727 [25600/60000]\n",
      "loss:1.673314 [32000/60000]\n",
      "loss:1.706450 [38400/60000]\n",
      "loss:1.597343 [44800/60000]\n",
      "loss:1.631254 [51200/60000]\n",
      "loss:1.520404 [57600/60000]\n",
      "Test Error:\n",
      " Accuracy:61.0%, Avg loss:0.000000\n",
      "\n",
      "Epoch4\n",
      "--------------\n",
      "loss:1.604844 [    0/60000]\n",
      "loss:1.561270 [ 6400/60000]\n",
      "loss:1.409194 [12800/60000]\n",
      "loss:1.478168 [19200/60000]\n",
      "loss:1.369245 [25600/60000]\n",
      "loss:1.357435 [32000/60000]\n",
      "loss:1.383262 [38400/60000]\n",
      "loss:1.294240 [44800/60000]\n",
      "loss:1.339921 [51200/60000]\n",
      "loss:1.232477 [57600/60000]\n",
      "Test Error:\n",
      " Accuracy:63.0%, Avg loss:0.000000\n",
      "\n",
      "Epoch5\n",
      "--------------\n",
      "loss:1.338100 [    0/60000]\n",
      "loss:1.309972 [ 6400/60000]\n",
      "loss:1.145814 [12800/60000]\n",
      "loss:1.246811 [19200/60000]\n",
      "loss:1.130440 [25600/60000]\n",
      "loss:1.156114 [32000/60000]\n",
      "loss:1.184764 [38400/60000]\n",
      "loss:1.109076 [44800/60000]\n",
      "loss:1.155204 [51200/60000]\n",
      "loss:1.066700 [57600/60000]\n",
      "Test Error:\n",
      " Accuracy:64.6%, Avg loss:0.000000\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch{t+1}\\n--------------')\n",
    "    train(train_dataloader,model,loss_fn,optimizer)\n",
    "    test(test_dataloader,model,loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed4536-ba71-45d3-b349-a472f3075353",
   "metadata": {},
   "source": [
    "# save models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e81b5814-5566-42b1-9133-56911b6191f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Pytorch Model State to model.path\n",
      "model's Parameters OrderedDict([('linear_relu_stack.0.weight', tensor([[ 0.0297, -0.0158, -0.0289,  ..., -0.0288, -0.0197,  0.0142],\n",
      "        [-0.0084,  0.0065, -0.0120,  ..., -0.0133, -0.0108,  0.0124],\n",
      "        [-0.0010, -0.0313, -0.0148,  ..., -0.0247, -0.0208,  0.0346],\n",
      "        ...,\n",
      "        [ 0.0272,  0.0235, -0.0144,  ...,  0.0215, -0.0350,  0.0063],\n",
      "        [-0.0310, -0.0343,  0.0075,  ...,  0.0189,  0.0085,  0.0152],\n",
      "        [-0.0135,  0.0090,  0.0074,  ...,  0.0264,  0.0356,  0.0026]],\n",
      "       device='cuda:0')), ('linear_relu_stack.0.bias', tensor([-3.2084e-03, -2.6568e-02, -2.4015e-02,  1.9518e-02,  2.6756e-02,\n",
      "         1.2515e-02,  2.0961e-02, -3.2916e-02, -2.2673e-02, -2.6601e-02,\n",
      "        -1.8379e-02,  4.0674e-02,  1.6384e-02, -1.0032e-02, -9.0005e-03,\n",
      "        -4.2968e-03,  3.1889e-02,  2.9030e-03, -1.4166e-02, -1.1304e-02,\n",
      "        -1.8850e-02, -3.4805e-02, -2.6738e-02,  1.7201e-02, -1.4999e-02,\n",
      "         3.4140e-02, -3.3903e-02,  1.1548e-02,  8.3324e-04, -1.6668e-02,\n",
      "         3.8087e-02, -2.4879e-02,  2.7325e-02, -2.9087e-02,  6.8579e-03,\n",
      "         2.9881e-02,  3.7049e-02, -1.8706e-02, -2.0022e-02,  3.2324e-03,\n",
      "        -2.9041e-03,  1.2614e-02, -2.8753e-02,  9.0030e-03, -1.5779e-04,\n",
      "        -7.1774e-03, -8.7404e-05,  2.3790e-02, -1.4102e-02, -1.0631e-02,\n",
      "         1.9345e-02, -2.0337e-02,  3.9554e-03, -4.4923e-03,  1.0763e-03,\n",
      "         1.7934e-02,  1.1875e-02, -5.7500e-03, -6.4691e-03, -6.1607e-03,\n",
      "         1.9587e-02, -2.9020e-02,  2.9579e-02, -2.6253e-02, -9.1242e-03,\n",
      "         3.2701e-02, -3.2385e-02,  2.5548e-03, -1.6450e-02, -2.7849e-02,\n",
      "         4.6264e-03,  3.1085e-03, -2.7384e-02, -9.9366e-03, -2.4397e-02,\n",
      "         2.5351e-02,  1.2061e-02, -2.9580e-03, -2.5715e-02,  3.1487e-02,\n",
      "        -3.4098e-02,  3.4871e-02,  2.0630e-02,  2.2681e-02,  1.1982e-02,\n",
      "        -3.0093e-02, -6.3365e-03, -7.8224e-03, -1.7830e-02,  2.4551e-02,\n",
      "        -1.9387e-02, -1.9115e-02,  2.1038e-02, -2.3443e-02, -1.8618e-02,\n",
      "        -4.9560e-04, -2.6004e-02, -7.6364e-03,  2.3851e-02,  1.4995e-02,\n",
      "        -1.0996e-02,  1.0035e-02,  3.4742e-02,  2.6577e-02,  3.5607e-02,\n",
      "         2.9789e-03,  3.4109e-02,  6.5585e-03,  6.4629e-03,  1.8423e-02,\n",
      "        -3.2349e-02, -3.1068e-02,  1.9767e-02,  1.8665e-02, -2.0457e-02,\n",
      "         3.0649e-02,  2.9790e-02, -2.8960e-02,  3.3685e-02,  2.9344e-02,\n",
      "         2.5322e-02,  2.7872e-02, -2.4063e-02, -2.5354e-02, -6.4621e-03,\n",
      "         3.1159e-02, -1.6739e-02,  1.9193e-02,  3.4884e-02,  2.3538e-02,\n",
      "         2.7340e-02,  3.1235e-02,  2.4419e-02, -3.0274e-02,  6.3683e-03,\n",
      "        -2.4832e-02, -1.8618e-02,  3.1386e-03, -3.4204e-02, -4.6527e-03,\n",
      "        -2.2786e-02, -3.0302e-02,  2.3901e-02,  8.8691e-04, -2.1716e-02,\n",
      "        -8.0532e-03, -5.3037e-03, -2.1344e-02,  2.5051e-03, -1.8322e-02,\n",
      "         4.6908e-04,  2.1750e-02,  3.3207e-03, -2.4983e-02,  3.5732e-02,\n",
      "         1.3827e-02,  1.0240e-02, -1.5097e-02,  6.6507e-03, -4.7990e-04,\n",
      "        -2.0975e-02,  2.9727e-02,  6.1625e-03, -2.0969e-02, -2.1594e-02,\n",
      "        -4.1695e-03,  2.1671e-02, -6.3389e-03,  4.7746e-03, -2.7290e-02,\n",
      "         2.9901e-02,  2.2405e-02, -2.0436e-03, -1.5620e-02, -1.6576e-02,\n",
      "         1.1988e-02,  3.0470e-02,  2.5371e-02, -4.3483e-03,  1.4780e-02,\n",
      "        -4.4447e-03, -2.4505e-02,  2.8890e-02, -5.4120e-03,  3.8823e-03,\n",
      "         2.3127e-02,  1.9268e-02,  1.3327e-02,  4.5544e-02, -2.0439e-03,\n",
      "         2.1291e-02,  2.9291e-02,  1.4002e-02, -2.4083e-02,  5.6609e-03,\n",
      "        -2.0427e-02, -4.1408e-03, -3.2341e-02,  4.8459e-03,  1.0992e-02,\n",
      "         2.2969e-03,  1.7206e-02,  5.8979e-03, -3.3109e-02, -7.6866e-03,\n",
      "        -7.4034e-03,  1.4195e-02, -1.9971e-02,  1.4938e-02, -1.8279e-02,\n",
      "         3.9926e-02,  2.8837e-02, -2.1854e-02, -2.8368e-02, -2.0497e-02,\n",
      "         1.5917e-02, -1.2164e-02, -3.4115e-02,  1.9313e-02, -5.2779e-04,\n",
      "         7.3607e-03,  3.8667e-02, -2.2500e-03, -2.6048e-02, -1.3052e-03,\n",
      "         1.2191e-02, -7.3289e-03,  2.0543e-02, -2.7027e-02, -1.4596e-02,\n",
      "         1.6064e-02,  3.2046e-02,  1.7603e-02,  1.7175e-02, -7.1080e-03,\n",
      "        -4.6115e-03,  3.3746e-02,  2.0892e-02, -3.5178e-02, -2.3602e-02,\n",
      "        -1.2015e-02,  3.3334e-02,  1.0740e-03, -2.4323e-02,  2.2189e-02,\n",
      "         2.2342e-02, -6.5745e-03, -2.1608e-02,  1.7691e-02,  3.1667e-02,\n",
      "        -8.1687e-03,  9.8281e-03, -1.9551e-02,  3.1297e-02, -2.7940e-02,\n",
      "         1.3733e-02,  2.2181e-02,  2.8333e-02, -2.3134e-02, -2.0877e-02,\n",
      "        -2.1977e-03,  2.6506e-02,  3.1761e-02,  4.0276e-02,  3.8328e-02,\n",
      "         1.6174e-02, -2.1716e-02, -3.1995e-02, -3.2838e-02, -5.7724e-03,\n",
      "        -2.2254e-02, -2.1513e-02,  2.3444e-02,  6.2451e-04, -1.9767e-02,\n",
      "         2.6745e-02, -1.9109e-02,  1.4732e-02,  1.9326e-03, -2.2425e-02,\n",
      "        -3.2314e-02,  2.8251e-02,  4.3253e-03,  1.1706e-02,  2.6500e-02,\n",
      "        -2.7924e-02,  2.6034e-02, -2.3030e-02,  1.2309e-02,  1.4675e-02,\n",
      "        -1.9179e-02,  1.1066e-02, -2.6345e-02, -2.9279e-04, -2.6305e-03,\n",
      "        -3.9232e-03, -6.4145e-03,  1.2838e-02,  2.5821e-03, -2.7012e-02,\n",
      "         7.8815e-04,  3.0849e-02,  3.4951e-03,  2.3243e-02,  1.4138e-02,\n",
      "        -2.8692e-02, -2.4570e-02,  4.2293e-02,  2.7641e-02,  7.7425e-03,\n",
      "         4.1477e-02, -2.9383e-03,  2.9395e-02,  1.1653e-02,  1.9242e-02,\n",
      "         8.9685e-03,  1.0282e-02, -2.3543e-02,  2.8109e-02, -7.7465e-03,\n",
      "         2.5019e-02, -2.9842e-02,  1.0317e-02,  3.2147e-03,  3.7133e-02,\n",
      "        -2.0352e-02, -1.9241e-02,  2.3650e-02,  2.2125e-02,  3.2151e-02,\n",
      "         3.1268e-02, -1.3279e-02, -2.7588e-02, -2.6233e-02,  1.6878e-02,\n",
      "         1.9497e-03,  3.0820e-02,  1.9612e-02, -1.1775e-03, -4.9616e-03,\n",
      "        -1.4883e-02, -1.7023e-04, -2.9071e-03, -1.0177e-02, -1.0625e-02,\n",
      "        -3.0437e-02, -3.4980e-02, -1.6168e-02,  3.4425e-02,  1.7475e-03,\n",
      "         8.2626e-03,  9.0176e-03, -8.2770e-04,  3.8333e-02, -1.6005e-02,\n",
      "         1.9644e-02,  2.7024e-02,  2.6238e-02,  1.8429e-02, -1.9035e-02,\n",
      "        -4.7024e-03, -2.1340e-02, -4.9886e-03, -5.1997e-03,  2.6204e-02,\n",
      "         3.3862e-02, -8.8733e-03,  3.7026e-02, -7.5387e-04, -2.8229e-02,\n",
      "         6.6041e-03, -1.2064e-02, -5.3073e-05,  1.6718e-02, -3.4651e-02,\n",
      "         3.7341e-04,  2.4503e-02,  1.5378e-03, -2.1636e-04,  3.1068e-02,\n",
      "        -6.3853e-03, -2.6756e-02, -1.7076e-02,  2.8963e-02,  1.9321e-02,\n",
      "        -2.5058e-02, -1.0968e-02, -2.1049e-02,  2.6837e-02,  3.0679e-02,\n",
      "        -3.1966e-02, -8.9642e-03,  9.9293e-03,  2.9789e-02,  3.2142e-03,\n",
      "        -1.8542e-03,  1.8474e-02,  2.1941e-02,  1.5086e-02, -1.4919e-02,\n",
      "         7.1294e-03,  3.1314e-02, -3.1800e-02,  3.1540e-02,  2.3483e-02,\n",
      "         6.5966e-03,  2.4863e-02,  1.4131e-02, -4.1810e-03, -4.0013e-03,\n",
      "         2.9850e-02, -2.0572e-02,  3.7203e-04, -3.4515e-02,  2.4894e-02,\n",
      "         1.3064e-02, -1.4499e-03,  2.6328e-02,  3.6564e-02,  2.2144e-02,\n",
      "         1.0217e-02,  3.4294e-02,  1.8864e-02, -3.7926e-03,  1.4380e-02,\n",
      "         2.4946e-02,  3.0632e-02, -1.9000e-02, -2.0407e-02, -3.1952e-02,\n",
      "         1.9063e-02, -2.3753e-02, -9.8438e-03,  4.0798e-02, -2.6847e-02,\n",
      "         3.8295e-02, -9.4437e-03,  2.0222e-02, -2.2709e-02, -5.0974e-03,\n",
      "        -9.5388e-03, -8.9952e-03, -2.7583e-02,  2.5716e-02,  3.5878e-02,\n",
      "        -6.3162e-03, -1.3396e-02,  1.5568e-02,  1.6074e-02,  1.7909e-02,\n",
      "        -1.5082e-02,  1.6311e-02, -2.9143e-02, -1.6747e-03, -3.7758e-03,\n",
      "         2.4651e-02, -3.2719e-02,  9.9031e-03, -1.9491e-02, -1.8027e-02,\n",
      "         2.2671e-02,  1.4821e-03,  1.4449e-02, -1.2824e-03, -2.5856e-03,\n",
      "        -2.4057e-02, -1.6520e-03, -1.9872e-02, -1.8184e-02,  2.4894e-02,\n",
      "         1.3016e-02,  1.1277e-02,  1.1401e-02,  3.2856e-02, -2.6208e-02,\n",
      "         1.3784e-02, -1.8282e-02,  3.5775e-02, -2.1546e-02,  9.7226e-03,\n",
      "         1.5335e-02, -6.6970e-03,  3.5996e-02,  1.7113e-02,  2.3260e-02,\n",
      "         9.9897e-04,  1.0767e-02, -1.8407e-02,  3.9549e-02, -1.5598e-02,\n",
      "        -1.6646e-02, -3.2443e-02, -3.0354e-02,  3.7146e-02, -1.8698e-02,\n",
      "        -2.9060e-02, -3.4431e-02, -1.9928e-02, -3.2645e-03,  2.8602e-04,\n",
      "         7.0032e-03,  3.3703e-02,  1.1098e-03,  2.4148e-02,  1.8691e-02,\n",
      "         1.9717e-02, -1.3829e-02, -1.9041e-02,  2.9607e-02, -2.9477e-02,\n",
      "         4.2769e-03,  2.1412e-02], device='cuda:0')), ('linear_relu_stack.2.weight', tensor([[ 0.0225, -0.0108,  0.0102,  ..., -0.0226,  0.0330, -0.0067],\n",
      "        [-0.0255,  0.0139, -0.0296,  ...,  0.0389,  0.0138, -0.0198],\n",
      "        [ 0.0387,  0.0287, -0.0275,  ...,  0.0338,  0.0124, -0.0429],\n",
      "        ...,\n",
      "        [ 0.0406, -0.0350, -0.0259,  ..., -0.0084,  0.0224, -0.0075],\n",
      "        [ 0.0232, -0.0099, -0.0089,  ...,  0.0310, -0.0382, -0.0148],\n",
      "        [-0.0148,  0.0194,  0.0281,  ..., -0.0188, -0.0119, -0.0281]],\n",
      "       device='cuda:0')), ('linear_relu_stack.2.bias', tensor([ 8.7867e-03,  1.9754e-02,  2.1553e-02,  4.3128e-02, -4.2342e-02,\n",
      "         1.0247e-02, -2.1680e-02, -3.8509e-02, -3.0974e-03, -1.5629e-03,\n",
      "        -3.5703e-02,  2.8686e-02, -8.8994e-03,  3.6448e-02, -3.0564e-02,\n",
      "         2.6114e-02,  2.0992e-02, -3.2723e-03, -1.2861e-02,  1.3083e-02,\n",
      "         2.0932e-02, -9.2042e-03, -3.3681e-02, -1.6389e-02,  3.6357e-02,\n",
      "         6.1988e-02,  4.8097e-02, -4.5765e-04, -4.1387e-02, -2.5724e-02,\n",
      "         7.6291e-03,  1.3680e-03,  3.9354e-02,  3.3301e-02,  4.2854e-02,\n",
      "        -2.7151e-02, -4.4339e-03,  3.8816e-02,  2.0400e-02,  2.0313e-02,\n",
      "         1.0567e-02,  1.2204e-02,  1.3032e-02, -1.9086e-02, -3.6470e-02,\n",
      "        -3.5650e-02, -3.6440e-02, -1.4297e-02,  7.8539e-03, -2.0834e-02,\n",
      "        -3.7711e-03,  8.9500e-03,  2.2545e-02, -2.6333e-02,  9.4960e-03,\n",
      "        -2.9256e-02,  4.7228e-02, -4.8481e-03,  3.9403e-02,  2.9869e-02,\n",
      "         2.0636e-02,  2.1230e-02, -2.3780e-02,  1.6629e-02, -1.1094e-02,\n",
      "         1.9537e-02,  1.7968e-02,  3.8442e-02,  2.8775e-02, -2.4598e-02,\n",
      "         2.3863e-02,  1.7608e-02, -3.1103e-02, -1.5523e-03, -9.3748e-03,\n",
      "        -2.5475e-02,  3.5363e-02, -5.5347e-04, -4.0325e-02, -4.0537e-03,\n",
      "        -3.9590e-02,  2.2376e-03, -2.8610e-02, -4.8860e-03,  3.5941e-02,\n",
      "         3.5434e-02,  4.6805e-03, -1.6589e-02, -3.5264e-02,  5.5060e-03,\n",
      "         1.4855e-02, -5.0196e-02,  3.0603e-02, -9.7297e-03,  3.7862e-02,\n",
      "        -5.6770e-03, -7.7654e-03, -3.9543e-02,  3.2445e-02,  5.2449e-02,\n",
      "        -6.7122e-03,  2.6634e-02,  8.1089e-04, -3.2411e-02,  3.8050e-02,\n",
      "         1.3484e-02, -3.8750e-02,  3.2173e-02, -1.2508e-02,  4.9316e-02,\n",
      "         2.2044e-02, -3.7799e-02,  5.3298e-02,  4.3901e-02,  1.5300e-02,\n",
      "        -3.9087e-02, -2.3422e-02,  5.0378e-02,  1.1652e-02, -2.8126e-02,\n",
      "        -3.2422e-02, -2.4196e-02, -1.0566e-02,  1.1722e-02,  2.9320e-02,\n",
      "         4.4475e-02, -2.3365e-02, -8.5749e-03, -2.6007e-02, -6.9446e-03,\n",
      "        -4.1126e-02, -4.4785e-03, -6.4170e-03, -1.5152e-02,  7.2637e-03,\n",
      "         5.4093e-05,  8.9070e-03,  2.3473e-02,  2.8347e-03,  1.4890e-02,\n",
      "         1.7079e-02,  1.7367e-03,  4.0987e-02,  2.4758e-02,  1.1972e-02,\n",
      "         2.2291e-02,  2.9263e-03,  3.8228e-02,  2.3364e-02,  3.8056e-02,\n",
      "        -1.3753e-02, -1.8423e-02,  3.5684e-02, -3.5169e-03, -4.2092e-02,\n",
      "         4.2065e-02, -2.9909e-02, -1.4970e-03,  4.4446e-02, -6.5054e-03,\n",
      "        -1.8284e-02,  7.0856e-04, -1.5332e-02,  4.2104e-02,  1.4212e-02,\n",
      "        -3.5133e-02,  1.2604e-02, -3.3888e-02,  2.1723e-02, -1.1640e-02,\n",
      "         4.5666e-03,  3.2975e-02,  3.9761e-02,  5.7629e-02,  5.6168e-03,\n",
      "        -4.7791e-03,  3.0670e-02, -2.5160e-02, -3.1443e-02, -3.7470e-03,\n",
      "        -1.7293e-02, -9.8752e-03,  3.7435e-02, -2.1394e-02, -2.6733e-02,\n",
      "         3.8686e-02, -1.7790e-02,  4.2994e-03, -1.3318e-02,  4.7272e-02,\n",
      "        -2.9786e-02, -3.2903e-02,  1.8788e-02,  3.4224e-02,  2.1973e-03,\n",
      "         4.3165e-02, -2.2803e-02,  3.2833e-02,  8.3060e-03, -5.4198e-03,\n",
      "         8.6300e-03,  3.5923e-02,  1.8297e-02,  6.9790e-03,  1.8425e-02,\n",
      "         1.9141e-02,  4.5784e-02, -2.6704e-02, -1.0137e-02, -5.8801e-03,\n",
      "         1.0515e-02,  3.5731e-02,  1.2356e-03,  3.0510e-02,  1.1975e-02,\n",
      "         3.5399e-02, -3.3877e-02,  1.7788e-02,  1.3705e-02, -1.7129e-02,\n",
      "        -2.9169e-02, -1.0578e-02, -1.3266e-02,  4.0207e-02,  2.9324e-02,\n",
      "         4.9593e-02,  3.7537e-02,  3.7385e-02, -3.8298e-02, -5.9167e-03,\n",
      "         3.3767e-02, -2.5585e-02,  3.7823e-02, -2.2232e-02,  2.9078e-02,\n",
      "         4.4790e-02,  2.8892e-02,  1.0224e-02,  7.8309e-03, -2.9664e-02,\n",
      "         3.2211e-02, -1.3084e-02,  3.6147e-02,  4.5468e-03,  3.4925e-03,\n",
      "        -1.6590e-02,  4.9529e-02,  4.0536e-02,  1.1945e-02, -2.0648e-02,\n",
      "        -1.5894e-02, -8.5758e-03, -3.2346e-03,  3.6706e-02, -2.4215e-02,\n",
      "         1.7177e-02, -1.7577e-02,  1.9394e-03,  3.7698e-02, -2.0310e-02,\n",
      "         3.7238e-02, -3.6174e-02,  1.6943e-02,  3.2898e-03,  4.4375e-03,\n",
      "        -1.8995e-02, -5.6482e-03, -8.9274e-03, -1.7805e-02,  3.7602e-03,\n",
      "         1.3055e-02, -1.2231e-02,  2.3547e-02, -3.8353e-02,  2.1264e-03,\n",
      "        -3.1447e-02, -1.0323e-02, -1.2677e-02,  2.7262e-02,  2.0537e-02,\n",
      "         1.3869e-02,  3.5088e-02, -4.3305e-02, -3.5975e-02, -5.4323e-03,\n",
      "         1.1170e-02,  2.6323e-02, -1.5590e-03,  4.3507e-02,  1.2410e-03,\n",
      "        -2.9381e-02, -1.8303e-02,  2.4581e-02,  3.5220e-02, -3.6785e-02,\n",
      "         3.8362e-02, -1.5184e-02, -1.9504e-02, -2.2267e-02,  2.4615e-02,\n",
      "         1.0178e-02,  2.0759e-03, -1.9389e-02, -9.6929e-03,  7.1959e-03,\n",
      "        -2.7908e-02,  4.8674e-02,  1.0471e-03,  3.9431e-02, -3.5847e-02,\n",
      "        -8.6580e-03,  2.0435e-02,  2.1169e-02,  3.4128e-02,  1.1755e-02,\n",
      "        -1.0709e-02,  3.5174e-02,  2.7878e-02,  1.2252e-02, -4.6306e-02,\n",
      "        -3.1072e-02, -2.3492e-02,  3.1181e-02, -7.0360e-03, -2.8971e-02,\n",
      "        -2.5885e-02,  2.1707e-02, -2.4948e-02,  4.9145e-03,  4.3146e-03,\n",
      "         3.8052e-02, -3.7673e-02, -2.0013e-02,  3.9830e-02,  2.9871e-02,\n",
      "         2.8981e-02,  2.9011e-02, -1.5909e-02, -1.1714e-02,  3.9238e-02,\n",
      "         2.2205e-02, -2.1127e-02, -1.3818e-03,  4.0286e-02, -7.7292e-03,\n",
      "        -4.0017e-02,  3.4810e-02,  2.4015e-02,  2.5205e-02, -3.5670e-02,\n",
      "        -3.5322e-02, -1.3758e-02, -2.0532e-02,  3.5707e-03,  2.6793e-02,\n",
      "        -3.3584e-02,  1.5625e-02,  4.0635e-02,  4.7751e-02, -6.6656e-03,\n",
      "        -2.3100e-02,  1.2391e-02,  4.0008e-03,  2.2719e-02,  5.2962e-02,\n",
      "        -4.1080e-02, -3.6466e-03,  1.1894e-02,  1.0935e-02, -3.4180e-04,\n",
      "         3.8510e-02,  1.1770e-02,  6.7703e-03, -3.6478e-03, -1.7268e-02,\n",
      "        -3.0854e-02,  2.5410e-02, -2.4582e-02, -2.1990e-02,  5.4325e-03,\n",
      "        -7.3350e-03,  6.9033e-03, -3.4443e-02, -2.5214e-02,  3.3655e-02,\n",
      "         2.4866e-02,  9.3786e-03, -8.4614e-03,  1.1400e-02, -1.6971e-02,\n",
      "        -4.4400e-02,  2.0907e-02,  1.3149e-02,  3.5917e-02, -1.5486e-02,\n",
      "         2.3666e-02, -3.2574e-02,  4.1483e-02, -2.3007e-02, -9.7712e-05,\n",
      "         2.7572e-02,  2.2084e-02, -2.0309e-02,  7.2068e-03, -2.5513e-02,\n",
      "        -1.9866e-02, -2.2336e-02, -1.8453e-02, -4.3045e-03, -2.5294e-02,\n",
      "        -4.5675e-02, -2.7942e-02,  3.7266e-02, -1.6373e-02, -1.5695e-02,\n",
      "        -4.3062e-03,  3.1227e-02, -3.8489e-02, -3.4045e-02, -3.3664e-02,\n",
      "         3.4447e-02,  2.5235e-03,  8.8241e-03,  3.2627e-02, -3.9863e-02,\n",
      "         9.9830e-03,  4.1692e-02, -3.4267e-02, -1.8532e-02, -1.8660e-03,\n",
      "        -2.8342e-02, -1.1821e-02, -3.8962e-02, -1.9837e-02,  4.1496e-02,\n",
      "        -2.9452e-02, -1.3878e-02,  2.2914e-02, -1.8137e-02,  3.7416e-02,\n",
      "         2.9224e-02,  2.3174e-03, -5.7404e-03, -1.0926e-02,  4.5576e-02,\n",
      "         2.5665e-02,  1.2760e-02,  2.3697e-03, -1.3586e-02,  1.7498e-02,\n",
      "        -2.3688e-02, -1.4226e-02,  2.2786e-02, -1.0674e-02, -6.6801e-03,\n",
      "        -2.4792e-02, -3.3701e-02,  8.6078e-03,  3.2356e-02, -1.4036e-02,\n",
      "         3.1103e-03,  3.0431e-02, -7.6851e-03,  2.6170e-02,  4.4609e-02,\n",
      "         5.4136e-02, -3.8607e-02, -1.4386e-02, -1.0316e-02,  4.3433e-02,\n",
      "         2.1862e-02, -3.3263e-02, -5.1279e-03, -3.4883e-02, -4.6902e-02,\n",
      "         3.3021e-02,  1.0212e-02,  3.7765e-02,  4.1548e-03, -4.0163e-02,\n",
      "        -3.5639e-02, -2.3034e-02,  4.7925e-03, -3.5217e-02,  2.8395e-02,\n",
      "        -1.0155e-02,  1.9094e-02, -3.6549e-02,  4.3959e-02,  2.0909e-02,\n",
      "         3.3032e-02,  1.0849e-03,  6.4122e-03, -1.5595e-02, -3.2855e-02,\n",
      "         1.7799e-02,  5.8964e-02,  6.9457e-03,  1.0112e-02, -3.1389e-02,\n",
      "         1.0959e-02, -1.2343e-02,  4.7675e-03,  4.1191e-02,  2.0429e-02,\n",
      "         2.1932e-02,  3.8441e-02, -3.2168e-03,  4.3095e-02,  2.8073e-02,\n",
      "        -3.4231e-02, -3.9324e-02], device='cuda:0')), ('linear_relu_stack.4.weight', tensor([[-0.0016,  0.0385, -0.0119,  ...,  0.0049,  0.0261, -0.0715],\n",
      "        [ 0.0264,  0.0229,  0.0166,  ..., -0.0271,  0.0093,  0.0095],\n",
      "        [ 0.0303, -0.0267, -0.0190,  ..., -0.0374, -0.0298, -0.0450],\n",
      "        ...,\n",
      "        [-0.0066, -0.0362,  0.0213,  ...,  0.0381, -0.0557,  0.0156],\n",
      "        [-0.0319, -0.0048, -0.0061,  ...,  0.0710,  0.0304,  0.0525],\n",
      "        [-0.0266,  0.0805, -0.0335,  ..., -0.0131,  0.0327,  0.0098]],\n",
      "       device='cuda:0')), ('linear_relu_stack.4.bias', tensor([-0.0743,  0.0209, -0.0221, -0.0430, -0.0542,  0.1413, -0.0126,  0.0776,\n",
      "        -0.0047, -0.0265], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(),\"D:\\model.path\")\n",
    "print(\"Saved Pytorch Model State to model.path\")\n",
    "print(\"model's Parameters\",model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90116f4f-d651-4b27-a218-79c99f611151",
   "metadata": {},
   "source": [
    "# Loading Models:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f164213d-0f0e-425f-a966-9b2409552bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=NeuralNetwork()\n",
    "model.load_state_dict(torch.load(r\"D:\\model.path\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d94f023c-5f6e-47c5-9b68-f2680dc115f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\"Ankle boot\",Actual:\"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "#this model can now be used to make predictions\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "model.eval()\n",
    "x,y=test_data[0][0],test_data[0][1]  #x为test_data的数据值，y为test_data的真实标签索引\n",
    "with torch.no_grad():\n",
    "    pred=model(x)    #pred为各个标签预测的权重\n",
    "    predicted,actual=classes[pred[0].argmax(0)],classes[y]\n",
    "    print(f'Predicted:\"{predicted}\",Actual:\"{actual}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6fe06e-ae5b-4e83-83e1-3c6bc08747f1",
   "metadata": {},
   "source": [
    "# 核心方法&函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab20eb-26dc-416f-a06f-175e15201073",
   "metadata": {},
   "source": [
    "### ToTensor(): converts PIL image or Numpy ndarray into a FloatTensor.and scales the image's pixel intensity values in the range[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355ec2b-f592-474e-b881-891d3585a722",
   "metadata": {},
   "source": [
    "### transforms: to perform some manipulation of the data and make it suitable for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa4489-cb24-4e28-afe0-4bfffb2c750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    "#lambda:wo define a function to turn the integer into a one-hot encoded tensor.\n",
    "# It first creates a zero tensor of size 10 (the number of labels in our dataset) and call scatter_ \n",
    "# whch assigns a value=1 on the index as given by the label y."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
