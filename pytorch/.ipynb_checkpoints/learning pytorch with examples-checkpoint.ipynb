{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be77070c-f260-4765-b782-340a166ac1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec849cf-caa3-4c06-be06-42fc6bf81ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1614.9081429692362\n",
      "199 1101.5135659195748\n",
      "299 753.0656880145582\n",
      "399 516.309736198957\n",
      "499 355.2649457482324\n",
      "599 245.5967702270655\n",
      "699 170.8302544745673\n",
      "799 119.7997819568718\n",
      "899 84.92992363748047\n",
      "999 61.075440693313766\n",
      "1099 44.73781266584258\n",
      "1199 33.535544451059536\n",
      "1299 25.84568226961672\n",
      "1399 20.560945985353396\n",
      "1499 16.925014223518026\n",
      "1599 14.420692092799854\n",
      "1699 12.693899590145714\n",
      "1799 11.501949396224997\n",
      "1899 10.678312720340706\n",
      "1999 10.108589816779588\n",
      "Result:y=0.032214758966576086+0.8381651865978047x+-0.005557581977637425x^2+-0.0906881636651305x^3\n",
      "Wall time: 322 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import math\n",
    "# Create random input and output data\n",
    "x=np.linspace(-math.pi,math.pi,2000)\n",
    "y=np.sin(x)\n",
    "# Randomly initialize weights\n",
    "a=np.random.randn()\n",
    "b=np.random.randn()\n",
    "c=np.random.randn()\n",
    "d=np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    #迭代2000次\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred=a+b*x+c*x**2+d*x**3\n",
    "    loss=np.square(y_pred-y).sum()\n",
    "    # compute and print loss\n",
    "    if t%100==99:\n",
    "        print(t,loss)\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred=2.0*(y_pred-y) #由损失函数求导转化而来，计算梯度必须要现有损失函数\n",
    "    grad_a=grad_y_pred.sum()\n",
    "    grad_b=(grad_y_pred*x).sum()\n",
    "    grad_c=(grad_y_pred*x**2).sum()\n",
    "    grad_d=(grad_y_pred*x**3).sum()\n",
    "    #update weights\n",
    "    a-=learning_rate * grad_a\n",
    "    b-=learning_rate * grad_b\n",
    "    c-=learning_rate * grad_c\n",
    "    d-=learning_rate * grad_d\n",
    "print(f'Result:y={a}+{b}x+{c}x^2+{d}x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ded3bc7-a98c-49a2-945e-f1a499c0cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2303.4462890625\n",
      "199 1526.611328125\n",
      "299 1012.7960205078125\n",
      "399 672.93701171875\n",
      "499 448.1352844238281\n",
      "599 299.4358825683594\n",
      "699 201.07339477539062\n",
      "799 136.00643920898438\n",
      "899 92.96334838867188\n",
      "999 64.4886245727539\n",
      "1099 45.651084899902344\n",
      "1199 33.18854522705078\n",
      "1299 24.943374633789062\n",
      "1399 19.488147735595703\n",
      "1499 15.878701210021973\n",
      "1599 13.490352630615234\n",
      "1699 11.909989356994629\n",
      "1799 10.864179611206055\n",
      "1899 10.17208194732666\n",
      "1999 9.714048385620117\n",
      "Result: y = -0.0040124827064573765 + 0.8278629779815674 x + 0.0006922206957824528 x^2 + -0.08922275900840759 x^3\n",
      "Wall time: 691 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import math\n",
    "dtype=torch.float\n",
    "device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "x=torch.linspace(-math.pi,math.pi,2000,device=device,dtype=dtype)\n",
    "y=torch.sin(x)\n",
    "#randomly initialize wights\n",
    "a=torch.randn((),device=device,dtype=dtype)\n",
    "b=torch.randn((),device=device,dtype=dtype)\n",
    "c=torch.randn((),device=device,dtype=dtype)\n",
    "d=torch.randn((),device=device,dtype=dtype)\n",
    "learning_rate=1e-6\n",
    "for t in range(2000):\n",
    "    y_pred=a+b*x+c*x**2+d*x**3\n",
    "    #compute and print loss\n",
    "    loss=(y_pred-y).pow(2).sum().item()\n",
    "    if t%100==99:\n",
    "        print(t,loss)\n",
    "    \n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred=2.0*(y_pred-y)\n",
    "    grad_a=grad_y_pred.sum()\n",
    "    grad_b=(grad_y_pred*x).sum()\n",
    "    grad_c=(grad_y_pred*x**2).sum()\n",
    "    grad_d=(grad_y_pred*x**3).sum()\n",
    "    # update weights using gradient descent\n",
    "    a-=learning_rate * grad_a\n",
    "    b-=learning_rate * grad_b\n",
    "    c-=learning_rate * grad_c\n",
    "    d-=learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f48ba-fed2-4303-9bc6-1b595515be83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
