{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "486eb4cc-5c28-4476-b574-2c6c671739ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "#注释脚本问torch官方文档，已不适用。\n",
    "# FILENAME = \"mnist.pkl.gz\"\n",
    "# if not (PATH / FILENAME).exists():\n",
    "#         content = requests.get(URL + FILENAME).content\n",
    "#         (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4f598de-dc6d-4d2c-bd6e-6b7199712ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c058f4-391a-478c-a2c3-b689b80cf362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pylab import plt\n",
    "import numpy as np\n",
    "plt.imshow(x_train[0].reshape((28,28)),cmap='gray')\n",
    "plt.show()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad648a32-9809-4b10-a80d-9eda33701b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math \n",
    "x_train,y_train,x_valid,y_valid=map(torch.tensor,(x_train,y_train,x_valid,y_valid))  #将arry转为tensor\n",
    "n,c=x_train.shape\n",
    "print(x_train,y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(),y_train.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2270dfd-88d8-4adb-9fa2-fdd02f6f683a",
   "metadata": {},
   "source": [
    "### xb@weights +bias 为线性函数，只能解决线性问题。因此需要用激活函数（曲线）对模型使用性进行加强\n",
    "### 神经网络层只有两三层,对于隐藏层, 使用任意的激励函数, 影响不大.但层数较多，对每个隐藏层使用梯度函数，会导致到梯度爆炸, 梯度消失的问题.\n",
    "### 在卷积神经网络 Convolutional neural networks 的卷积层中, 推荐relu. 在循环神经网络中 recurrent neural networks, 推荐 tanh 或者是 relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aff89db-58e5-4442-9d16-8cea630177ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.3432, -2.3242, -2.3374, -2.2420, -2.2141, -2.3659, -2.1773, -2.3520,\n",
      "        -2.3182, -2.3730], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "一张图片有1维784个数值组成，batchsize=64代表一次处理64张图片，preds.shape=[64,10],\n",
    "64代表每个图片的结果，10代表10个类别中，每个类别上的得分\n",
    "'''\n",
    "weights=torch.rand(784,10)/math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias=torch.zeros(10,requires_grad=True)\n",
    "\n",
    "# x.exp()为x的e次方；sum(-1)：按行求和，计算后为64个元素的数组\n",
    "# unsqueeze(-1) 将一维转为2维,转化后的shape为（64，1）\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)  \n",
    "\n",
    "# xb.shape(64,784),weights.shape(784,10); \n",
    "# xb @ weights之后的shape为(64,10)\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)  #@代表点积 , xb@weights +bias 为线性函数，只能解决线性问题。因此需要用激活函数（曲线）对模型进行加强\n",
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "preds = model(xb)  # predictions\n",
    "print(preds[0], preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb44f94c-1233-4291-aaeb-ac1052933b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2995, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义loss function\n",
    "# -input[range(target.shape[0]), target].mean():提取 -yreds[(0,64),yb]的平均值\n",
    "# 即提取64组训练样本预测结果的10个标签值对应的真实值Y标签值的平均值\n",
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()  #提取预测类别中与真实类别对应得分的均值\n",
    "# put loss function in loss_func\n",
    "loss_func = nll\n",
    "yb=y_train[0:bs]\n",
    "print(loss_func(preds,yb)) #损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f8f9d99-a80b-4672-b160-0cd215a4422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#上步计算损失函数用到此方法\n",
    "a=torch.tensor([[1,2,3,4],[2,3,4,5]])\n",
    "b=torch.tensor([2,3])\n",
    "a[range(2),b]  #提取a中第一行的2位置，第二行3位置的数值，只有tensor类型才有此方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fedadfde-3b6b-43f4-922c-5c526cda2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 8, 5, 9, 5, 4, 4, 4, 6, 4, 5, 0, 5, 5, 4, 4, 9, 7, 4, 0, 5, 8, 5,\n",
      "        7, 0, 8, 0, 8, 7, 8, 4, 5, 4, 4, 7, 9, 4, 9, 5, 4, 4, 8, 4, 5, 9, 6, 0,\n",
      "        5, 4, 4, 6, 8, 8, 7, 4, 6, 8, 0, 5, 9, 9, 0, 5])\n",
      "tensor(0.0625)\n"
     ]
    }
   ],
   "source": [
    "#计算64个样本的精度，即（预测值=目标值）的平均值\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    print(preds)\n",
    "    return (preds == yb).float().mean()\n",
    "print(accuracy(preds,yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17fa9ceb-f49c-4c94-914a-a2fb95855ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf683af6-ef4b-451c-a0b1-fecf4b56f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8])\n",
      "tensor(0.0817, grad_fn=<NegBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "lr=0.5 #learning rate\n",
    "epochs=2 #how many epochs to train for\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)// bs+1):   #//向下取整\n",
    "        start_i=i*bs\n",
    "        end_i=start_i+bs\n",
    "        xb=x_train[start_i:end_i]\n",
    "        yb=y_train[start_i:end_i]\n",
    "        pred=model(xb)\n",
    "        loss=loss_func(pred,yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad(): #torch.no_grad() 设置不记录梯度\n",
    "            weights -=weights.grad*lr\n",
    "            bias -=bias.grad*lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_() # 设置梯度为0，否则梯度每次会叠加，而非替换\n",
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8368d1-ba4d-40e2-9b02-2a6318f7ae91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e4fc582-948f-439e-a9a1-e3d443193d41",
   "metadata": {},
   "source": [
    "# pytorch方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f550b9b2-8a81-47e2-a75f-63b5984e5791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 3, 7, 0, 9, 0, 8, 5, 5, 2, 4, 5, 0, 8, 4, 8])\n",
      "tensor(-10.2498, grad_fn=<NegBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func==F.cross_entropy #F.cross_entropy 即交叉熵函数，其集成了损失函数和激活函数\n",
    "def model(xb):\n",
    "    return xb @ weights+bias \n",
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a0595b1-3555-4640-a906-e6e898c6e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 784])\n",
      "torch.Size([16])\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x0000014AD6F99F40>\n",
      "torch.Size([16, 784]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "#数据转换为张量，并进行处理，便于pttorch调用\n",
    "from torch.utils.data import TensorDataset\n",
    "print(xb.shape),print(yb.shape)\n",
    "#pythorch 处理数据提取test_data和label_data的方法\n",
    "train_ds=TensorDataset(x_train,y_train)\n",
    "print(train_ds)\n",
    "xb,yb=train_ds[i*bs:i*bs+bs]\n",
    "print(xb.shape,yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ecb5ab6-f9fe-428c-bcc5-0348015dc500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False],\n",
      "        [False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "d = torch.tensor([[1., 2.], [3., 4.]])\n",
    "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
    "print(torch.eq(d, e)) # returns a tensor of type bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dbe18f-7170-4f31-9c55-4b3296bb8437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca03a721-b677-40e2-b20b-dae11be8a2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 226, 226])\n",
      "torch.Size([1, 3, 226, 226])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,226, 226)\n",
    "b = a.unsqueeze(0)   #在指定索引位置添加一个维度\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "de512d5c-785d-4230-ba2f-b520d9f6baee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 321.6247863769531\n",
      "199 216.96766662597656\n",
      "299 147.38137817382812\n",
      "399 101.09713745117188\n",
      "499 70.30037689208984\n",
      "599 49.8006706237793\n",
      "699 36.149391174316406\n",
      "799 27.054662704467773\n",
      "899 20.992828369140625\n",
      "999 16.950428009033203\n",
      "1099 14.253448486328125\n",
      "1199 12.453060150146484\n",
      "1299 11.250513076782227\n",
      "1399 10.446823120117188\n",
      "1499 9.9093599319458\n",
      "1599 9.549703598022461\n",
      "1699 9.308860778808594\n",
      "1799 9.147469520568848\n",
      "1899 9.039238929748535\n",
      "1999 8.966598510742188\n",
      "Result: y = -0.006649009417742491 + 0.8465467691421509 x + 0.0011470644967630506 x^2 + -0.09188036620616913 x^3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "class Polynomial3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate four parameters and assign them as\n",
    "        member parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "\n",
    "    def string(self):\n",
    "        \"\"\"\n",
    "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
    "        \"\"\"\n",
    "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n",
    "\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = Polynomial3()\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters (defined \n",
    "# with torch.nn.Parameter) which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "for t in range(2000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d1a0e78-eb24-4628-a1ad-32adf2f61a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 1254.7108154296875\n",
      "3999 561.918701171875\n",
      "5999 252.7285919189453\n",
      "7999 116.67032623291016\n",
      "9999 56.68316650390625\n",
      "11999 29.891559600830078\n",
      "13999 18.116165161132812\n",
      "15999 12.92485237121582\n",
      "17999 10.631612777709961\n",
      "19999 9.602967262268066\n",
      "21999 9.17440128326416\n",
      "23999 8.9905366897583\n",
      "25999 8.935267448425293\n",
      "27999 8.868438720703125\n",
      "29999 8.859440803527832\n",
      "Result: y = 0.002161707729101181 + 0.8542189598083496 x + -0.000904913351405412 x^2 + -0.09324324876070023 x^3 + 0.0001232288486789912 x^4 ? + 0.0001232288486789912 x^5 ?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate five parameters and assign them as members.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "        self.e = torch.nn.Parameter(torch.randn(()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 4, 5\n",
    "        and reuse the e parameter to compute the contribution of these orders.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same parameter many\n",
    "        times when defining a computational graph.\n",
    "        \"\"\"\n",
    "        y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "        for exp in range(4, random.randint(4, 6)):\n",
    "            y = y + self.e * x ** exp\n",
    "        return y\n",
    "\n",
    "    def string(self):\n",
    "        \"\"\"\n",
    "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
    "        \"\"\"\n",
    "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3 + {self.e.item()} x^4 ? + {self.e.item()} x^5 ?'\n",
    "\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet()\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
    "for t in range(30000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 2000 == 1999:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139d2a0-7d9e-474e-8fe7-dc19cf33cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
